# Reasoning Engine Training Dependencies

# Core ML Framework
torch>=2.1.0
transformers>=4.36.0

# Quantization & LoRA
bitsandbytes>=0.41.0
peft>=0.7.0
accelerate>=0.25.0

# Training
trl>=0.7.0  # For SFT trainer utilities
datasets>=2.15.0

# Evaluation
matplotlib>=3.7.0
pandas>=2.0.0
seaborn>=0.12.0

# Utilities
tqdm>=4.66.0
numpy>=1.24.0

# Optional: FlashAttention for faster inference
# flash-attn>=2.3.0  # Uncomment if you have CUDA 11.8+
